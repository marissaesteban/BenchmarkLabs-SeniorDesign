{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "from seebuoy import NDBC\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm, skew, probplot\n",
    "from scipy.special import boxcox1p\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from datetime import datetime, timedelta\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Root Mean Squared Error (RMSE).\n",
    "    \n",
    "    Parameters:\n",
    "    y_true : array-like of shape (n_samples,)\n",
    "        Ground truth (correct) target values.\n",
    "        \n",
    "    y_pred : array-like of shape (n_samples,)\n",
    "        Estimated target values.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The RMSE value.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buoySetUp(buoyNum):  \n",
    "    ndbc = NDBC(timeframe=\"historical\")\n",
    "    df_avail = ndbc.available_data(station_id=buoyNum)\n",
    "    df_data = ndbc.get_data(buoyNum)\n",
    "\n",
    "    df_data.dropna(axis=1, how='all', inplace=True)\n",
    "    df_data = df_data.reset_index()\n",
    "\n",
    "    # lets limit the df to 2 columns: date and wave height\n",
    "    buoy_df = df_data[[\"date\",\"wave_height\", \"average_period\"]]\n",
    "\n",
    "    # Set 'date' column as the index\n",
    "    buoy_df = buoy_df.set_index(\"date\")\n",
    "\n",
    "    buoy_df['wave_height_interpolated'] = buoy_df['wave_height'].interpolate(method='time') # interpolate missing values based on time\n",
    "    buoy_df['average_period_interpolated'] = buoy_df['average_period'].interpolate(method='time') # interpolate missing values based on time\n",
    "\n",
    "    return buoy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doit(buoy_df, f, c, target, buoyNum):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    f : floor value, how many days back to train the model on\n",
    "\n",
    "    c : ceiling value, how many days we want to predict for (want 10-15 days)\n",
    "\n",
    "    target : either \"wave_height\" or \"average_period\". Variable we want to traiun and predict on.\n",
    "    \"\"\"\n",
    "    if target != \"wave_height\" and target != \"average_period\":\n",
    "        print(\"Not a valid target variable\")\n",
    "        return\n",
    "\n",
    "    #Sets up date objects and floor and ceiling\n",
    "    today_date = datetime.today().date()\n",
    "    floor = f + c\n",
    "    ceiling = c\n",
    "\n",
    "    # Calculate the floordate and the ceiling date\n",
    "    floorDate = today_date - timedelta(days=floor)\n",
    "    ceilingDate = today_date - timedelta(days=ceiling)\n",
    "\n",
    "    # Splits up the df into recent and past\n",
    "    # Recent holds the 15 most recent days of data\n",
    "    # Past holds all data from the floor to the ceiling\n",
    "    recent_df = buoy_df[buoy_df['date'] > pd.Timestamp(ceilingDate)]\n",
    "    past_df = buoy_df[(buoy_df['date'] > pd.Timestamp(floorDate)) & (buoy_df['date'] < pd.Timestamp(ceilingDate))]\n",
    "\n",
    "    #Sets up the modeling df with the date and target variable column as well as the cap for logistic growth prophet algo\n",
    "    modeling_df = past_df[[\"date\",f'{target}_interpolated']]\n",
    "    modeling_df = modeling_df.rename(columns={\"date\": \"ds\", f'{target}_interpolated': \"y\"})\n",
    "    cap = modeling_df['y'].max() + 1\n",
    "\n",
    "    # Initialize Prophet model with the cap\n",
    "    model = Prophet(growth=\"logistic\")\n",
    "    modeling_df['cap'] = cap\n",
    "    model.fit(modeling_df)\n",
    "\n",
    "    #Makes prediction\n",
    "    future = model.make_future_dataframe(periods=ceiling)\n",
    "    future['cap'] = cap\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    forecast['date'] = forecast['ds']\n",
    "    merged_df = pd.merge(forecast.tail(15), recent_df, on='date', how='left')\n",
    "\n",
    "    print(f\"RMSE for {buoyNum} for {ceiling} days using {floor - 15} days worth of training data for {target}\")\n",
    "    print(rmse(merged_df[f'{target}_interpolated'], merged_df[\"yhat\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:44:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:44:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 46239 for 15 days using 365 days worth of training data for wave_height\n",
      "0.7381412655699661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:45:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:45:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 46258 for 15 days using 365 days worth of training data for wave_height\n",
      "0.3796250863542164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:45:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:45:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 46232 for 15 days using 365 days worth of training data for wave_height\n",
      "0.4713763422654524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:46:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:46:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 42001 for 15 days using 365 days worth of training data for wave_height\n",
      "0.8409574676069215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:47:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:48:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 41002 for 15 days using 365 days worth of training data for wave_height\n",
      "0.9279168916864616\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['average_period'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m buoy_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m46239\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m46258\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m46232\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42001\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m41002\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m44037\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m44097\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m44009\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m41064\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buoyNum \u001b[38;5;129;01min\u001b[39;00m buoy_list:\n\u001b[0;32m----> 5\u001b[0m     buoy_df \u001b[38;5;241m=\u001b[39m \u001b[43mbuoySetUp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuoyNum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     buoy_df \u001b[38;5;241m=\u001b[39m buoy_df\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      7\u001b[0m     doit(buoy_df, \u001b[38;5;241m365\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwave_height\u001b[39m\u001b[38;5;124m\"\u001b[39m, buoyNum)\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mbuoySetUp\u001b[0;34m(buoyNum)\u001b[0m\n\u001b[1;32m      7\u001b[0m df_data \u001b[38;5;241m=\u001b[39m df_data\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# lets limit the df to 2 columns: date and wave height\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m buoy_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwave_height\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maverage_period\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Set 'date' column as the index\u001b[39;00m\n\u001b[1;32m     13\u001b[0m buoy_df \u001b[38;5;241m=\u001b[39m buoy_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/2024S/COMP492/Benchmark-Code/.venv/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/2024S/COMP492/Benchmark-Code/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/2024S/COMP492/Benchmark-Code/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['average_period'] not in index\""
     ]
    }
   ],
   "source": [
    "buoy_list = [\"46239\", \"46258\", \"46232\", \"42001\", \"41002\", \"44037\", \"44097\", \"44009\", \"41064\"]\n",
    "\n",
    "\n",
    "for buoyNum in buoy_list:\n",
    "    buoy_df = buoySetUp(buoyNum)\n",
    "    buoy_df = buoy_df.reset_index()\n",
    "    doit(buoy_df, 365, 15, \"wave_height\", buoyNum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "418da822878bf5e9e939dfb4ad40fe672876b0467fe6e10ad67d81e9a42cb991"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
